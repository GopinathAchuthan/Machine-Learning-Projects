# Supervised Learning

| **Model Type**              | **Purpose**                                  | **Key Characteristics**                               | **Examples**                                               | **Input Format**                          | **Output Format**                        |
|-----------------------------|----------------------------------------------|-------------------------------------------------------|------------------------------------------------------------|-------------------------------------------|------------------------------------------|
| **Regression Models**        | Predict continuous values                    | Predicts a continuous outcome; minimizes error        | Linear Regression, Ridge Regression, Lasso Regression, SVR | Continuous features (numerical)           | Continuous value (numerical)             |
| **Classification Models**    | Predict discrete classes or categories       | Predicts a discrete outcome; typically uses decision boundaries | Logistic Regression, SVM, Decision Trees, k-NN, Naive Bayes, Neural Networks | Features (continuous or categorical)      | Class label (discrete category)          |
| **Ensemble Learning**        | Combine multiple models for better accuracy  | Aggregates the predictions of multiple models         | Random Forest, AdaBoost, Gradient Boosting, XGBoost, Stacking | Features (continuous or categorical)      | Class label or continuous value (depends on model) |
| **Bayesian Models**          | Use probabilistic approach with prior knowledge | Models uncertainty in predictions using Bayes' theorem | Naive Bayes, Bayesian Linear Regression, Gaussian Naive Bayes | Features (continuous or categorical)      | Probabilities or class label (discrete)  |
| **Neural Networks / Deep Learning** | Learn complex patterns from data, especially large-scale data | Uses layers of neurons for feature extraction and transformation | CNNs (image), RNNs, LSTMs (time-series), Transformers (NLP) | Raw data (images, sequences, etc.)        | Class label or continuous value (depending on task) |
| **Decision Models**          | Make decisions by splitting the data into subsets based on features | Builds a tree-like structure for decision making      | CART, C4.5, CHAID, C5.0 | Features (continuous or categorical)      | Class label or continuous value (depends on model) |
| **Instance-based Models**    | Store and compare specific data instances    | Classifies based on similarity to training instances  | k-NN, Locally Weighted Learning | Features (continuous or categorical)      | Class label or continuous value (based on nearest neighbors) |
| **Nonlinear Models**         | Handle complex, nonlinear relationships      | Model data where relationships are not linear         | SVM with Kernel, Nonlinear Decision Trees | Features (continuous or categorical)      | Class label or continuous value          |
| **Multi-output Models**      | Predict multiple outcomes simultaneously     | Handles cases where there are multiple dependent variables | Multi-output Regression, Multi-class Classification (One-vs-Rest, One-vs-One) | Features (continuous or categorical)      | Multiple target values (continuous or categorical) |
| **Specialized Models**       | Handle specific types of tasks               | Focuses on specialized problems or data structures    | Ordinal Regression, RankNet, Instance Selection | Features (continuous or categorical)      | Ordinal value (for Ordinal Regression) or ranked output (for RankNet) |

